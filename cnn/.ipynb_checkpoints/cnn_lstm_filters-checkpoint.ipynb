{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import files\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from Bio import SeqIO\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pdb\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "# ENcoding\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, model_from_config\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input, merge, LSTM, Merge\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers import normalization\n",
    "from keras.layers.convolutional import Conv1D,Convolution2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Bidirectional, concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,Convolution1D, MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# plfold\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "from os import listdir\n",
    "from  __builtin__ import any\n",
    " \n",
    "\n",
    "def read_seq(seq_file,plfold):\n",
    "    seq_list = []\n",
    "    seq = ''\n",
    "    with open(seq_file, 'r') as fp:\n",
    "        for line in fp:\n",
    "            if line[0] == '>':\n",
    "                name = line[1:-1]\n",
    "                if len(seq):\n",
    "                    seq_array = get_RNA_seq_concolutional_array(seq, name, plfold)\n",
    "                    seq_list.append(seq_array)                    \n",
    "                seq = ''\n",
    "            else:\n",
    "                seq = seq + line[:-1]\n",
    "        if len(seq):\n",
    "            seq_array = get_RNA_seq_concolutional_array(seq, name, plfold)\n",
    "            seq_list.append(seq_array) \n",
    "    \n",
    "    return np.array(seq_list)\n",
    "\n",
    "def load_label_seq(seq_file):\n",
    "    label_list = []\n",
    "    seq = ''\n",
    "    with open(seq_file, 'r') as fp:\n",
    "        for line in fp:\n",
    "            if line[0] == '>':\n",
    "                name = line[1:-1]\n",
    "                posi_label = name.split(';')[-1]\n",
    "                label = posi_label.split(':')[-1]\n",
    "                label_list.append(int(label))\n",
    "    return np.array(label_list)\n",
    "\n",
    "def get_RNA_seq_concolutional_array(seq, key, plfold, motif_len = 10):\n",
    "    seq = seq.replace('U', 'T')\n",
    "#     alpha = 'acgu'\n",
    "    alpha = 'ACGT'\n",
    "#     print seq\n",
    "    half_len = motif_len/2\n",
    "    row = (len(seq) + half_len *2 )\n",
    "    new_array = np.zeros((row, 5))\n",
    "\n",
    "#     First and last half_len values set to 0.25\n",
    "\n",
    "    for i in range(half_len):\n",
    "        new_array[i] = np.array([0.25]*5)\n",
    "    \n",
    "    for i in range(row-half_len, row):\n",
    "        new_array[i] = np.array([0.25]*5)    \n",
    "\n",
    "        \n",
    "    for i, val in enumerate(seq):\n",
    "#         print i,val\n",
    "        i = i + half_len\n",
    "#         print i,val\n",
    "#         if val not in 'acgu':\n",
    "        if val not in 'ACGT':\n",
    "            new_array[i] = np.array([0.25]*5)\n",
    "            continue\n",
    "        #if val == 'N' or i < motif_len or i > len(seq) - motif_len:\n",
    "        #    new_array[i] = np.array([0.25]*4)\n",
    "        #else:\n",
    "        try:\n",
    "            index = alpha.index(val)\n",
    "            new_array[i][index] = 1\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        #data[key] = new_array\n",
    "        \n",
    "#         using the key, find the file in the given protein directory\n",
    "#  Extract probabilities, then take sum of squares of probabilities and put in the array\n",
    "\n",
    "    for name in plfold:\n",
    "        if name == key:\n",
    "            for i, val in enumerate(seq):\n",
    "#                 i = i + half_len\n",
    "                new_array[i + half_len][4] = plfold[name][i]\n",
    "        \n",
    "    return new_array\n",
    "\n",
    "def load_data_file(inputfile, plfold, seq = True, onlytest = False):\n",
    "    \"\"\"\n",
    "        Load data matrices from the specified folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = os.path.dirname(inputfile)\n",
    "    data = dict()\n",
    "    if seq: \n",
    "        tmp = []\n",
    "        tmp.append(read_seq(inputfile, plfold))\n",
    "#         seq_onehot, structure = read_structure(inputfile, path)\n",
    "#         tmp.append(seq_onehot)\n",
    "        data[\"seq\"] = tmp\n",
    "#         data[\"structure\"] = structure\n",
    "    if onlytest:\n",
    "        data[\"Y\"] = []\n",
    "    else:\n",
    "        data[\"Y\"] = load_label_seq(inputfile)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def split_training_validation(classes, validation_size, shuffle = True):\n",
    "    \"\"\"split sampels based on balnace classes\"\"\"\n",
    "    num_samples=len(classes)\n",
    "    classes=np.array(classes)\n",
    "    classes_unique=np.unique(classes)\n",
    "    num_classes=len(classes_unique)\n",
    "    indices=np.arange(num_samples)\n",
    "    #indices_folds=np.zeros([num_samples],dtype=int)\n",
    "    training_indice = []\n",
    "    training_label = []\n",
    "    validation_indice = []\n",
    "    validation_label = []\n",
    "    for cl in classes_unique:\n",
    "        indices_cl=indices[classes==cl]\n",
    "        num_samples_cl=len(indices_cl)\n",
    "\n",
    "        # split this class into k parts\n",
    "        if shuffle:\n",
    "            random.shuffle(indices_cl) # in-place shuffle\n",
    "        \n",
    "        # module and residual\n",
    "        num_samples_each_split=int(num_samples_cl*validation_size)\n",
    "        res=num_samples_cl - num_samples_each_split\n",
    "        \n",
    "        training_indice = training_indice + [val for val in indices_cl[num_samples_each_split:]]\n",
    "        training_label = training_label + [cl] * res\n",
    "        \n",
    "        validation_indice = validation_indice + [val for val in indices_cl[:num_samples_each_split]]\n",
    "        validation_label = validation_label + [cl]*num_samples_each_split\n",
    "\n",
    "    training_index = np.arange(len(training_label))\n",
    "    random.shuffle(training_index)\n",
    "    training_indice = np.array(training_indice)[training_index]\n",
    "    training_label = np.array(training_label)[training_index]\n",
    "    \n",
    "    validation_index = np.arange(len(validation_label))\n",
    "    random.shuffle(validation_index)\n",
    "    validation_indice = np.array(validation_indice)[validation_index]\n",
    "    validation_label = np.array(validation_label)[validation_index]    \n",
    "    \n",
    "            \n",
    "    return training_indice, training_label, validation_indice, validation_label    \n",
    " \n",
    "\n",
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder\n",
    "\n",
    "def calculate_performace(test_num, pred_y,  labels):\n",
    "    tp =0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC \n",
    "\n",
    "\n",
    "def list_files(directory, extension):\n",
    "    return (f for f in listdir(directory) if f.endswith('.' + extension))\n",
    "\n",
    "\n",
    "def list_dir(path):\n",
    "    proteinList=[]\n",
    "    files = os.listdir(path)\n",
    "    for name in files:\n",
    "        proteinList.append(name)\n",
    "    return proteinList\n",
    "\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_network_new(name, training, y, validation, val_y, batch_size=50, nb_epoch=30):\n",
    "    print 'configure cnn network'\n",
    "    \n",
    "    rows=111\n",
    "    cols=5\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    input_shape = Input(shape=(rows,cols))\n",
    "    tower_1 = Conv1D(16, 10, padding='valid', activation='relu')(input_shape) \n",
    "    tower_temp = Activation('relu')(tower_1)\n",
    "    pool = MaxPooling1D(pool_size=3, padding='valid')(tower_temp)\n",
    "    lstm = Bidirectional(LSTM(64))(pool)\n",
    "    lstm = Dropout(0.10)(lstm)\n",
    "#     flat = Flatten()(pool)\n",
    "#     out = Dense(200, activation='relu')(flat)\n",
    "    out = Dense(50, activation='relu')(lstm)\n",
    "    out = Dense(2, activation='sigmoid')(out)\n",
    "    model = Model(input_shape, out)\n",
    " \n",
    "\n",
    "    history = History()\n",
    "    \n",
    "    model.compile(loss=\n",
    "#                   'kullback_leibler_divergence'\n",
    "                  'categorical_crossentropy'\n",
    "                  , optimizer=RMSprop(lr=0.001),metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    plot_model(model, to_file='architecture/%s.png'%(name))\n",
    "    \n",
    "    #tensorboard = TensorBoard(log_dir='Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    #pdb.set_trace()\n",
    "    print 'model training'\n",
    "\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "\n",
    "    history = model.fit(training, y, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(validation, val_y)\n",
    "              , callbacks=[history\n",
    "                           ,earlystopper\n",
    "                           #,tensorboard\n",
    "                          ])\n",
    "\n",
    "    return model, history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = \"/mnt/mirror/data/mimtiy/lab/encode/data/proteins/\"\n",
    "proteins = list_dir(dir_path)\n",
    "\n",
    "train_path=\"/30000/training_sample_0/\"\n",
    "test_path =\"/30000/test_sample_0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with the code (With Structural Features)\n",
      "******************************************************\n",
      "# 1  - Protein:  18_ICLIP_hnRNPL_Hela_group_3975_all-hnRNPL-Hela-hg19_sum_G_hg19--ensembl59_from_2337-2339-741_bedGraph-cDNA-hits-in-genome\n",
      "******************************************************\n",
      "Training Examples:  (30000,)\n",
      "Test Examples:  (10000,)\n",
      "Train Set Dimensions:  (30000, 111, 5)\n",
      "Test Set Dimensions:  (10000, 111, 5)\n"
     ]
    }
   ],
   "source": [
    "print \"Starting with the code (With Structural Features)\" \n",
    "\n",
    "#for protein in proteins:\n",
    "# for i in range(1):\n",
    "i=1\n",
    "protein = proteins[i]\n",
    "print \"******************************************************\"\n",
    "print \"#\", i ,\" - Protein: \", protein\n",
    "print \"******************************************************\"\n",
    "    \n",
    "    #protein = proteins[0]\n",
    "\n",
    "train_ps_path = dir_path + protein + train_path + 'plfold'\n",
    "train_file_path = dir_path + protein + train_path + 'sequences.fa'\n",
    "test_ps_path = dir_path + protein + test_path + 'plfold'\n",
    "test_file_path = dir_path + protein + test_path + 'sequences.fa'\n",
    "\n",
    "#     train_seq_dict = read_pl_seq(train_file_path)\n",
    "#     train_plfold = getStructDict(train_ps_path,train_seq_dict)    \n",
    "#     saving struct dict in pickle\n",
    "#     test_seq_dict = read_pl_seq(test_file_path)\n",
    "#     test_plfold = getStructDict(test_ps_path,test_seq_dict)\n",
    "    \n",
    "with open('pickle/train_plfold_%s.pickle'%(protein), 'rb') as handle:\n",
    "    train_plfold = pickle.load(handle)\n",
    "with open('pickle/test_plfold_%s.pickle'%(protein), 'rb') as handle:\n",
    "    test_plfold = pickle.load(handle)\n",
    "        \n",
    "training_data = load_data_file(train_file_path, train_plfold)\n",
    "test_data = load_data_file(test_file_path, test_plfold)\n",
    "\n",
    "    #Saving to Label and Seq \n",
    "train_Y = training_data[\"Y\"]\n",
    "test_label = test_data[\"Y\"]\n",
    "seq_data = training_data[\"seq\"][0]\n",
    "seq_test = test_data[\"seq\"][0]\n",
    "\n",
    "\n",
    "print \"Training Examples: \", train_Y.shape\n",
    "print \"Test Examples: \", test_label.shape\n",
    "print \"Train Set Dimensions: \", seq_data.shape\n",
    "print \"Test Set Dimensions: \", seq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "training_indice, training_label, validation_indice, validation_label = split_training_validation(train_Y,0.2, False)\n",
    "seq_train = seq_data[training_indice]\n",
    "seq_validation = seq_data[validation_indice] \n",
    "\n",
    "print \"Training Set Shape: \", seq_train.shape, training_label.shape\n",
    "print \"Validation Set Shape: \", seq_validation.shape, validation_label.shape\n",
    "print \"Test Set Shape: \", seq_test.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure cnn network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 111, 5)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 102, 16)           816       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 102, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 34, 16)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 48,840\n",
      "Trainable params: 48,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model training\n",
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "24000/24000 [==============================] - 42s - loss: 0.4817 - acc: 0.7989 - val_loss: 0.4687 - val_acc: 0.8007\n",
      "Epoch 2/30\n",
      "24000/24000 [==============================] - 44s - loss: 0.4635 - acc: 0.8024 - val_loss: 0.4641 - val_acc: 0.8000\n",
      "Epoch 3/30\n",
      "24000/24000 [==============================] - 43s - loss: 0.4553 - acc: 0.8051 - val_loss: 0.4645 - val_acc: 0.7977\n",
      "Epoch 4/30\n",
      "24000/24000 [==============================] - 46s - loss: 0.4497 - acc: 0.8080 - val_loss: 0.4646 - val_acc: 0.8032\n",
      "Epoch 5/30\n",
      "24000/24000 [==============================] - 38s - loss: 0.4458 - acc: 0.8087 - val_loss: 0.4572 - val_acc: 0.7977\n",
      "Epoch 6/30\n",
      "24000/24000 [==============================] - 44s - loss: 0.4404 - acc: 0.8120 - val_loss: 0.4565 - val_acc: 0.8000\n",
      "Epoch 7/30\n",
      "24000/24000 [==============================] - 42s - loss: 0.4377 - acc: 0.8130 - val_loss: 0.4549 - val_acc: 0.8052\n",
      "Epoch 8/30\n",
      "24000/24000 [==============================] - 42s - loss: 0.4330 - acc: 0.8129 - val_loss: 0.4719 - val_acc: 0.7923\n",
      "Epoch 9/30\n",
      "24000/24000 [==============================] - 44s - loss: 0.4321 - acc: 0.8129 - val_loss: 0.4568 - val_acc: 0.8003\n",
      "Epoch 10/30\n",
      "24000/24000 [==============================] - 43s - loss: 0.4281 - acc: 0.8149 - val_loss: 0.4711 - val_acc: 0.7888\n",
      "Epoch 11/30\n",
      "24000/24000 [==============================] - 44s - loss: 0.4249 - acc: 0.8170 - val_loss: 0.4598 - val_acc: 0.8037\n",
      "Epoch 12/30\n",
      "24000/24000 [==============================] - 44s - loss: 0.4218 - acc: 0.8181 - val_loss: 0.4624 - val_acc: 0.8067\n",
      "Epoch 13/30\n",
      "24000/24000 [==============================] - 42s - loss: 0.4186 - acc: 0.8203 - val_loss: 0.4577 - val_acc: 0.8027\n",
      "Model took 571.38 seconds to train\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn1Lstm+struct'\n",
    "batch_size= 50 \n",
    "nb_epoch = 30\n",
    "# seq_data = []\n",
    "\n",
    "y, encoder = preprocess_labels(training_label)\n",
    "val_y, encoder = preprocess_labels(validation_label, encoder = encoder) \n",
    "test_y, encoder = preprocess_labels(test_label)\n",
    "\n",
    "# training_data.clear()\n",
    "\n",
    "start = time.time()\n",
    "model, history = run_network_new(name, seq_train, y, validation = seq_validation,val_y = val_y, batch_size=batch_size, nb_epoch = nb_epoch)\n",
    "end = time.time()\n",
    "\n",
    "print \"Model took %0.2f seconds to train\"%(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(history.history.keys())\n",
    "# print(history.history['val_acc'])\n",
    "# plot_model_history(history).savefig(\"figure/%s_%s.png\"%(protein,name))\n",
    "\n",
    "\n",
    "# Evaluate the trained model on the test set!\n",
    "\n",
    "print \"Accuracy of Test Set:\", model.evaluate(seq_test,test_y, verbose=0)[1]\n",
    "\n",
    "\n",
    "predictions = model.predict(seq_test, verbose=0)\n",
    " # print predictions\n",
    "auc = roc_auc_score(test_y, predictions)\n",
    "print \"Test AUC: \", auc\n",
    "\n",
    "print \"******************************************************\"\n",
    "print \"#\", i ,\" - Protein: \", protein\n",
    "print \"******************************************************\"\n",
    "train_path = dir_path + protein + \"/30000/training_sample_0/sequences.fa\"\n",
    "test_path = dir_path + protein + \"/30000/test_sample_0/sequences.fa\"\n",
    "\n",
    "# print load_data_file(train_path)['Y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e93a28ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_label, 20,  facecolor='green')\n",
    "plt.ylabel('Number of PWMs')\n",
    "plt.xlabel('Length of PWM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
